#version 460

#extension GL_KHR_vulkan_glsl : enable // Vulkan-specific syntax
#extension GL_GOOGLE_include_directive : enable // Include files
#extension GL_EXT_ray_tracing : enable // Raytracing
#extension GL_EXT_debug_printf : enable

// Include structs and bindings
#ifndef includes
#define includes
#include "../../foray/src/shaders/rt_common/bindpoints.glsl"
#include "../../foray/src/shaders/common/camera.glsl"
#include "../../foray/src/shaders/rt_common/tlas.glsl"
#include "../../foray/src/shaders/rt_common/imageoutput.glsl"
#include "../../foray/src/shaders/common/lcrng.glsl"
#include "../../foray/src/shaders/common/noisetex.glsl"
#include "../../foray/src/shaders/rt_common/tracerconfig.glsl"
#endif

layout(binding = 11,  set = 0) readonly uniform RestirConfiguration
{
    /// @brief Current frames projection matrix
    mat4   PrevFrameProjectionViewMatrix;
    vec4   CameraPos;
    uvec2  ScreenSize;
    uint   ReservoirSize;
    uint   Frame;
    uint   InitialLightSampleCount;
    uint   TemporalSampleCountMultiplier;
    float  SpatialPosThreshold;
    float  SpatialNormalThreshold;
    uint   SpatialNeighbors;
    float  SpatialRadius;
    uint   Flags;
	uint   NumTriLights;
}
RestirConfig;


//# i nclude "../structs.hpp"
struct TriLight
    {
        vec4  p1;
        vec4  p2;
        vec4  p3;
		vec4  normal;
        uint  materialIndex;
		uint  reserved1;
		uint  reserved2;
		uint  reserved3;
    };
#include "restir/restirUtils.glsl"

layout(set = 1, binding = 0) buffer Reservoirs{ Reservoir reservoirs[]; } reservoirs;
layout(set = 1, binding = 1) buffer PrevFrameReservoirs { Reservoir prevFrameReservoirs[]; } prevFrameReservoirs;

#define GBUFFER_ALBEDO 0
#define GBUFFER_NORMAL 1
#define GBUFFER_POS 2
#define GBUFFER_MOTION 3
#define GBUFFER_DEPTH 4
layout(set = 0, binding = 14) uniform sampler2D GBufferTextures[5];

#define PREVIOUSFRAME_ALBEDO 0
#define PREVIOUSFRAME_NORMAL 1
#define PREVIOUSFRAME_POS 2
#define PREVIOUSFRAME_DEPTH 3
layout(set = 0, binding = 15) uniform sampler2D PreviousFrameImages[4];
layout(std140, set = 0, binding = 16) buffer TriLights{ TriLight triLights[]; } triLights;

// Declare hitpayloads

#define HITPAYLOAD_OUT
#include "../../foray/src/shaders/rt_common/payload.glsl"

layout (location = 2) rayPayloadEXT bool isShadowed;

vec3 pickPointOnTriangle(float r1, float r2, vec3 p1, vec3 p2, vec3 p3) {

//	mat4 ProjMat      = Camera.ProjectionMatrix;
//    mat4 ViewMat      = Camera.ViewMatrix;
//
//	p1 = (ProjMat * ViewMat * vec4(p1, 1)).xyz;
//	p2 = (ProjMat * ViewMat * vec4(p2, 1)).xyz;
//	p3 = (ProjMat * ViewMat * vec4(p3, 1)).xyz;

	float sqrt_r1 = sqrt(r1);
	return (1.0 - sqrt_r1) * p1 + (sqrt_r1 * (1.0 - r2)) * p2 + (r2 * sqrt_r1) * p3;
}

bool testVisibility(vec3 p1, vec3 p2) {
	float tMin = 0.001f;
	vec3 dir = p2 - p1;

	isShadowed = true;

	float curTMax = length(dir);
	dir /= curTMax;

	traceRayEXT(
		MainTlas,            // acceleration structure
		gl_RayFlagsTerminateOnFirstHitEXT | gl_RayFlagsOpaqueEXT | gl_RayFlagsSkipClosestHitShaderEXT,       // rayFlags
		0xFF,           // cullMask
		1,              // sbtRecordOffset
		0,              // sbtRecordStride
		1,              // missIndex
		p1,             // ray origin
		tMin,           // ray min range
		dir,            // ray direction
		curTMax - 2.0f * tMin,           // ray max range
		2               // payload (location = 0)
	);

	return isShadowed;
}

void main() 
{

	//vec4 n = triLights.triLights[5].normal;
	//debugPrintfEXT("triLight shader %f,%f,%f,%f \n", n.x, n.y, n.z, n.w);

	uvec2 pixelCoord = gl_LaunchIDEXT.xy;

	const vec2 pixelCenter = vec2(pixelCoord) + vec2(0.5);
	const vec2 inUV = pixelCenter/vec2(gl_LaunchSizeEXT.xy);
	vec2 d = inUV * 2.0 - 1.0;

	vec4 origin = Camera.InverseViewMatrix * vec4(0,0,0,1);
	vec4 target = Camera.InverseProjectionMatrix * vec4(d.x, d.y, 1, 1) ;
	vec4 direction = Camera.InverseViewMatrix*vec4(normalize(target.xyz), 0) ;

	float tmin = 0.001;
	float tmax = 10000.0;

    ChildPayload = ConstructHitPayload();

	ivec2 texSize = textureSize(NoiseSource, 0);

	ivec2 texel = ivec2(pixelCoord.x % texSize.x, pixelCoord.y % texSize.y);

	uint left = TracerConfig.RngSeed;
	uint right = texelFetch(NoiseSource, texel, 0).x;
	for (int i = 0; i < 4; i++)
	{
		uint temp = left & 0xFFFF | (right << 16);
		temp = lcgUint(temp) * lcgUint(temp);
		right += left;
		left += temp;
	}
	ChildPayload.Seed = left + right;

	uint randomSeed = left + right;

    traceRayEXT(MainTlas, 0, 0xff, 0, 0, 0, origin.xyz, tmin, direction.xyz, tmax, 0);

	imageStore(ImageOutput, ivec2(pixelCoord.xy), vec4(ChildPayload.Radiance, 1.0));

	// testing reservoirs
	vec4 color = vec4((prevFrameReservoirs.prevFrameReservoirs[0].numStreamSamples % 255) / 255.0f);
	reservoirs.reservoirs[0].numStreamSamples = prevFrameReservoirs.prevFrameReservoirs[0].numStreamSamples + 1;

	// test gbuffer 
	vec3 albedo = texelFetch(GBufferTextures[GBUFFER_ALBEDO], ivec2(pixelCoord), 0).xyz;
	vec3 worldPos = texelFetch(GBufferTextures[GBUFFER_POS], ivec2(pixelCoord), 0).xyz;
	vec3 worldNormal = texelFetch(GBufferTextures[GBUFFER_NORMAL], ivec2(pixelCoord), 0).xyz;
	imageStore(ImageOutput, ivec2(pixelCoord.xy), vec4(albedo, 1));

	// testing depth buffers
	uint arrayLoc = pixelCoord.y * RestirConfig.ScreenSize.x + pixelCoord.x;
	//debugPrintfEXT("x=%d, y=%d", RestirConfig.ScreenSize.x, RestirConfig.ScreenSize.y);
	float prevFrameDepth = texelFetch(PreviousFrameImages[PREVIOUSFRAME_DEPTH], ivec2(pixelCoord), 0).x;
	//prevFrameDepthBufferWrite.depth[arrayLoc] =  lcgFloat(randomSeed); mod(prevFrameDepthBufferRead.depth[arrayLoc] + 1/255.f,1.0f);

	imageStore(ImageOutput, ivec2(pixelCoord), vec4(prevFrameDepth, prevFrameDepth, prevFrameDepth, 1));

	float depth = texelFetch(GBufferTextures[GBUFFER_DEPTH], ivec2(pixelCoord), 0).x;

	Reservoir res = newReservoir();

	//debugPrintfEXT("RESTIR CONFIG initla sample count = %d", RestirConfig.InitialLightSampleCount);
	// RestirConfig
	vec3 lightSamplePos2;
	uint selected;
	for (int i = 0; i < RestirConfig.InitialLightSampleCount; ++i) {

		float lightSampleProb;
		// chose a triangle with importance sampling by light power
		//aliasTableSample(randFloat(rand), randFloat(rand), selected_idx, lightSampleProb);
		lightSampleProb = 1.0f/32.0f; // probabiliy that light was sampled?

		uint randomNr = lcgUint(randomSeed);
		//debugPrintfEXT(" randomnr = %d \n", randomNr);
		uint selected_idx = randomNr % RestirConfig.NumTriLights;
		//debugPrintfEXT("light index % d \n", selected_idx);
		vec4 lightNormal;

		// pick a random point on the triangle light
		// debug: triangle index 11 always yields 0.

		TriLight light = triLights.triLights[selected_idx];
		vec3 lightSamplePos = pickPointOnTriangle(lcgFloat(randomSeed), lcgFloat(randomSeed), light.p1.xyz, light.p2.xyz, light.p3.xyz);
		lightSamplePos2 = lightSamplePos;
		selected = selected_idx;
		// TODO: calculate luminance from material id
		// lightSampleLum = light.emission_luminance.w;
		float lightSampleLum = 1.0;

		vec3 wi = normalize(worldPos - lightSamplePos);
		vec3 normal = normalize(vec3(light.normal.xyz));

		// lights that don't face surface are discarded?
		float normalToLight = clamp(dot(wi, normal), 0, 1);
		float triangleAreaSize = light.normal.w; // the bigger the triangle, the smaller the probability
		lightSampleProb /= normalToLight * triangleAreaSize; // the worse the normalToLight angle, the smaller the probability
		
		//debugPrintfEXT("normalToLightFactor %f, triangleAreaSize %f, lightSampleProb %f \n", normalToLight, triangleAreaSize,lightSampleProb);
		lightNormal = vec4(normal, 1.0f);


		// evaluate light emission, based on view angle and material brdf
//		float pHat = evaluatePHat(
//			worldPos, lightSamplePos, uniforms.cameraPos.xyz,
//			normal, lightNormal.xyz, lightNormal.w > 0.5f,
//			albedoLum, lightSampleLum, roughnessMetallic.x, roughnessMetallic.y
//		);
		float pHat = 1.0f;

		addSampleToReservoir(res, lightSamplePos, lightNormal, lightSampleLum, selected_idx, pHat, lightSampleProb, randomSeed);
	}

	// print Reservoir
	//debugPrintfEXT("light index %d , X:%f Y:%f Z:%f \n", selected, lightSamplePos2.x,lightSamplePos2.y,lightSamplePos2.z);
	//struct LightSample {
//		vec4 position_emissionLum;
//		vec4 normal;
//		uint lightIndex;
//		float pHat;
//		float sumWeights;
//		float w;
//	};

//	uint reservoirIndex = pixelCoord.y * uniforms.screenSize.x + pixelCoord.x;

	// Visibility Reuse (toggle ?)
	bool shadowed = true;
	if(true)
	{
		for (int i = 0; i < RESERVOIR_SIZE; i++) {
			shadowed = testVisibility(worldPos, res.samples[i].position_emissionLum.xyz);
			//shadowed = testVisibility(worldPos, lightSamplePos2);
			//debugPrintfEXT(" shadowed = %d \n", shadowed);
			if (shadowed) {
				res.samples[i].w = 0.0f;
				res.samples[i].sumWeights = 0.0f;
			}
		}
	}

	imageStore(ImageOutput, ivec2(pixelCoord), vec4(!shadowed));

	// scale motion range 0..1 to ScreenSize space
	vec2 screenSize = vec2(RestirConfig.ScreenSize);
	vec2 motion = texelFetch(GBufferTextures[GBUFFER_MOTION], ivec2(pixelCoord), 0).xy * screenSize;
	//debugPrintfEXT("screenSize = %f,%f \n", screenSize.x, screenSize.y);
	vec2 oldCoords = pixelCoord + motion;

	vec3 oldWorldPos = texelFetch(PreviousFrameImages[PREVIOUSFRAME_POS], ivec2(oldCoords), 0).xyz;

	//imageStore(ImageOutput, ivec2(pixelCoord), vec4(worldPos-oldWorldPos,1)); // trippy colors

	// just doesn't work.
//	vec4 prevFramePos = RestirConfig.PrevFrameProjectionViewMatrix * vec4(worldPos, 1.0f);
//	prevFramePos.xyz /= prevFramePos.w;
//	prevFramePos.xy = (prevFramePos.xy + 1.0f) * 0.5f * vec2(RestirConfig.ScreenSize);
//	oldWorldPos = prevFramePos.xyz;
//
	bool positionDiffValid = false;
	bool normalDiffValid = false;
	bool albedoDiffValid = false;
	if(
		all(greaterThanEqual(oldCoords.xy, vec2(0.0f))) &&
		all(lessThanEqual(oldCoords.xy, screenSize))
	)
	{
		vec3 positionDiff = worldPos-oldWorldPos;
		if (dot(positionDiff, positionDiff) < 0.1f) {
			positionDiffValid = true;
		}

		vec3 oldNormal = texelFetch(PreviousFrameImages[PREVIOUSFRAME_NORMAL], ivec2(oldCoords), 0).xyz;
		vec3 normalDiff = worldNormal - oldNormal;
		if (dot(normalDiff, normalDiff) < 0.1f) {
			normalDiffValid = true;
		}
		vec3 oldAlbedo = texelFetch(PreviousFrameImages[PREVIOUSFRAME_ALBEDO], ivec2(oldCoords), 0).xyz;
		vec3 albedoDiff = albedo - oldAlbedo;
		if (dot(albedoDiff, albedoDiff) < 0.1f) {
			albedoDiffValid = true;
		}
	}

	bool usePositionDiff = true;
	bool useNormalDiff = true;
	bool useAlbedoDiff = true;

	// TEMPORAL REUSE
	if(positionDiffValid && normalDiffValid && albedoDiffValid)
	{
		uvec2 prevFragCoords = uvec2(oldCoords);
		Reservoir prevRes = prevFrameReservoirs.prevFrameReservoirs[prevFragCoords.y * RestirConfig.ScreenSize.x + prevFragCoords.x];

		// clamp the number of samples
		prevRes.numStreamSamples = min(
			prevRes.numStreamSamples, 200
		);

		//vec2 metallicRoughness = texelFetch(uniMaterialProperties, ivec2(pixelCoord), 0).xy;

		// this is a reevluation of the light influence from previous samples.

		float pHat[RESERVOIR_SIZE];
		for (int i = 0; i < RESERVOIR_SIZE; ++i) {
//			pHat[i] = evaluatePHat(
//				worldPos, prevRes.samples[i].position_emissionLum.xyz, uniforms.cameraPos.xyz,
//				normal, prevRes.samples[i].normal.xyz, prevRes.samples[i].normal.w > 0.5f,
//				albedoLum, prevRes.samples[i].position_emissionLum.w, metallicRoughness.x, metallicRoughness.y
//			);
			pHat[i] = 1.0f;
		}

		combineReservoirs(res, prevRes, pHat, randomSeed);
	}

	uint reservoirIndex = pixelCoord.y * RestirConfig.ScreenSize.x + pixelCoord.x;
	reservoirs.reservoirs[reservoirIndex] = res;
	
	// shade pixel by usin Reservoir
//	struct LightSample {
//	vec4 position_emissionLum;
//	vec4 normal;
//	uint lightIndex;
//	float pHat;
//	float sumWeights;
//	float w;
//};
//
//struct Reservoir {
//	LightSample samples[RESERVOIR_SIZE];
//	uint numStreamSamples;
//};


	//debugPrintfEXT("Brightness pHat %f , number of samples %d \n", res.samples[0].pHat, res.numStreamSamples);
	vec4 finalColor = vec4(vec3(res.samples[0].pHat) * albedo,1.0f);
	imageStore(ImageOutput, ivec2(pixelCoord), vec4(finalColor));
	imageStore(ImageOutput, ivec2(pixelCoord), vec4(!shadowed));
//	imageStore(ImageOutput, ivec2(pixelCoord), vec4(!shadowed));
//	if(colorGreen&&colorRed&&colorBlue)
//	{
//		imageStore(ImageOutput, ivec2(pixelCoord), vec4(1,0,1,1));
//	}
//	else if(colorGreen)
//	{
//		imageStore(ImageOutput, ivec2(pixelCoord), vec4(0,1,0,1));
//	}
//	else if(colorRed)
//	{
//		imageStore(ImageOutput, ivec2(pixelCoord), vec4(1,0,0,1));
//	}
//	else if(colorBlue)
//	{
//		imageStore(ImageOutput, ivec2(pixelCoord), vec4(0,0,1,1));
//	}

//	// Temporal reuse
//	if (1) 
//	{
//		vec4 prevFramePos = uniforms.prevFrameProjectionViewMatrix * vec4(worldPos, 1.0f);
//		prevFramePos.xyz /= prevFramePos.w;
//		prevFramePos.xy = (prevFramePos.xy + 1.0f) * 0.5f * vec2(uniforms.screenSize);
//		if (
//			all(greaterThan(prevFramePos.xy, vec2(0.0f))) &&
//			all(lessThan(prevFramePos.xy, vec2(uniforms.screenSize)))
//		) {
//			ivec2 prevFrag = ivec2(prevFramePos.xy);
//
//#ifdef COMPARE_DEPTH
//			float depthDiff = prevFramePos.z - texelFetch(uniPrevDepth, prevFrag, 0).x;
//			if (depthDiff < 0.001f * prevFramePos.z) {
//#else
//			// highest quality results can be obtained by directly comparing the world positions
//			// the performance impact of this is unclear
//			vec3 positionDiff = worldPos - texelFetch(uniPrevFrameWorldPosition, prevFrag, 0).xyz;
//			if (dot(positionDiff, positionDiff) < 0.01f) {
//#endif
//				vec3 albedoDiff = albedo - texelFetch(uniPrevFrameAlbedo, prevFrag, 0).rgb;
//				if (dot(albedoDiff, albedoDiff) < 0.01f) {
//					float normalDot = dot(normal, texelFetch(uniPrevFrameNormal, prevFrag, 0).xyz);
//					if (normalDot > 0.5f) {
//						Reservoir prevRes = prevFrameReservoirs[prevFrag.y * uniforms.screenSize.x + prevFrag.x];
//
//						// clamp the number of samples
//						prevRes.numStreamSamples = min(
//							prevRes.numStreamSamples, uniforms.temporalSampleCountMultiplier * res.numStreamSamples
//						);
//
//						vec2 metallicRoughness = texelFetch(uniMaterialProperties, ivec2(pixelCoord), 0).xy;
//
//						float pHat[RESERVOIR_SIZE];
//						for (int i = 0; i < RESERVOIR_SIZE; ++i) {
//							pHat[i] = evaluatePHat(
//								worldPos, prevRes.samples[i].position_emissionLum.xyz, uniforms.cameraPos.xyz,
//								normal, prevRes.samples[i].normal.xyz, prevRes.samples[i].normal.w > 0.5f,
//								albedoLum, prevRes.samples[i].position_emissionLum.w, metallicRoughness.x, metallicRoughness.y
//							);
//						}
//
//						combineReservoirs(res, prevRes, pHat, rand);
//					}
//				}
//			}
//		}
//	}
//
//	reservoirs[reservoirIndex] = res;
}
